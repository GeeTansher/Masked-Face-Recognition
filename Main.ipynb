{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28415,"status":"ok","timestamp":1667836792146,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"MxeMvqqvyghZ","outputId":"ea725f2d-9e9e-49bb-b111-08da7ce9555d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1529,"status":"ok","timestamp":1667836734566,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"rtCQ6KwiyXF4"},"outputs":[],"source":["import cv2\n","import os\n","import matplotlib.pyplot as plt\n","import glob\n","# import face_recognition\n","import numpy as np\n","import joblib\n","import uuid\n","import seaborn as sns"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3528,"status":"ok","timestamp":1667836738086,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"MH9Rq-sAyXF-"},"outputs":[],"source":["from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.models import load_model, Model\n","from keras.applications.vgg16 import VGG16\n","from tensorflow.keras.layers import Flatten\n","import imutils"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1667836738088,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"3MVu0KU7yXF_"},"outputs":[],"source":["SIZE = 240"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305127,"status":"ok","timestamp":1667837101928,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"chtkemDuyXGA","outputId":"94dfc926-6c6e-4ae2-bedc-149bba398c50"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Daniel Radcliffe\n","50\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Alia Bhatt\n","50\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Aishwarya Rai\n","49\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Darshan Raval\n","46\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Gal Gadot\n","48\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Honey Singh\n","45\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Emma Watson\n","50\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Hrithik Roshan\n","47\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Sharukh Khan\n","47\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Kaley Cuoco\n","49\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Mr. Bean\n","46\n","/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Billie Eilish\n","44\n"]}],"source":["# Training data and labels into respective lists\n","train_images = []\n","train_labels = []\n","prev=0\n","\n","for directory_path in glob.glob(\"/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/*\"):\n","    label = directory_path.split(\"\\\\\")[-1]\n","    print(label)\n","    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n","        # print(img_path)\n","        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n","        img = cv2.resize(img, (SIZE, SIZE))\n","        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n","        train_images.append(img)\n","        train_labels.append(label)\n","    print(len(train_images)-prev)\n","    prev=len(train_images)\n","        \n","train_images = np.array(train_images)\n","train_labels = np.array(train_labels)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1667837101930,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"rqb-ZsiezzIl","outputId":"b76d3994-28d6-4db9-c08a-8d6cefbc02be"},"outputs":[{"data":{"text/plain":["571"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(train_labels)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1667837101932,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"Vvf5_k8_yXGC"},"outputs":[],"source":["#Encode labels from text to integers.\n","from sklearn import preprocessing\n","encoder = preprocessing.LabelEncoder()\n","encoder.fit(train_labels)\n","train_labels_encoded = encoder.transform(train_labels)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1667837101933,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"nqlltNRCyXGC"},"outputs":[],"source":["x_train, y_train = train_images, train_labels_encoded\n","# Normalize pixel values to between 0 and 1\n","x_train = x_train / 255.0"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1667837101934,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"xH8_BGRJyXGD"},"outputs":[],"source":["from keras.utils import to_categorical\n","y_train_one_hot = to_categorical(y_train)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":924,"status":"ok","timestamp":1667837234781,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"Czkk6SmyzGIx"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=45)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5423,"status":"ok","timestamp":1667837245189,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"p4L6_YZCyXGE","outputId":"3d087f75-1411-4d01-faa7-59ae6eefb547"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 2s 0us/step\n"]}],"source":["# Loading model\n","VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1667837245191,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"6biadpvkyXGF"},"outputs":[],"source":["for layer in VGG_model.layers:\n","\tlayer.trainable = False\n","    \n","x=Flatten()(VGG_model.output)\n","VGG_model = Model(inputs=VGG_model.input, outputs=x)\n","\n","# VGG_model.summary()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21613,"status":"ok","timestamp":1667837271368,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"NVr6vBXgyXGG","outputId":"0e0348a5-33d3-432d-adc8-842d1526f0f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 13s 284ms/step\n"]}],"source":["# feature_extractor=VGG_model.predict(x_train)\n","features=VGG_model.predict(X_train)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667837350002,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"fJ_JuVsqyXGH"},"outputs":[],"source":["#RANDOM FOREST\n","from sklearn.ensemble import RandomForestClassifier\n","RF_model = RandomForestClassifier(n_estimators = 100, random_state = 42)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":883,"status":"ok","timestamp":1667837353415,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"wdcKNEMiyXGI","outputId":"7061bef8-47b8-4cb2-ac4e-0eedf4c2bd8e"},"outputs":[{"data":{"text/plain":["RandomForestClassifier(random_state=42)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["RF_model.fit(features, Y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kxtcIFcyXGI"},"outputs":[],"source":["def detect_and_predict_mask(frame, faceNet, maskNet):\n","\t# grab the dimensions of the frame and then construct a blob\n","\t# from it\n","\t(h, w) = frame.shape[:2]\n","\tblob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),\n","\t\t(104.0, 177.0, 123.0))\n","\n","\t# pass the blob through the network and obtain the face detections\n","\tfaceNet.setInput(blob)\n","\tdetections = faceNet.forward()\n","\tprint(detections.shape)\n","\n","\t# initialize our list of faces, their corresponding locations,\n","\t# and the list of predictions from our face mask network\n","\tfaces = []\n","\tlocs = []\n","\tpreds = []\n","\n","\t# loop over the detections\n","\tfor i in range(0, detections.shape[2]):\n","\t\t# extract the confidence (i.e., probability) associated with\n","\t\t# the detection\n","\t\tconfidence = detections[0, 0, i, 2]\n","\n","\t\t# filter out weak detections by ensuring the confidence is\n","\t\t# greater than the minimum confidence\n","\t\tif confidence > 0.5:\n","\t\t\t# compute the (x, y)-coordinates of the bounding box for\n","\t\t\t# the object\n","\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n","\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n","\n","\t\t\t# ensure the bounding boxes fall within the dimensions of\n","\t\t\t# the frame\n","\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n","\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n","\n","\t\t\t# extract the face ROI, convert it from BGR to RGB channel\n","\t\t\t# ordering, resize it to 224x224, and preprocess it\n","\t\t\tface = frame[startY:endY, startX:endX]\n","\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n","\t\t\tface = cv2.resize(face, (224, 224))\n","\t\t\tface = img_to_array(face)\n","\t\t\tface = preprocess_input(face)\n","\n","\t\t\t# add the face and bounding boxes to their respective\n","\t\t\t# lists\n","\t\t\tfaces.append(face)\n","\t\t\tlocs.append((startX, startY, endX, endY))\n","\n","\t# only make a predictions if at least one face was detected\n","\tif len(faces) > 0:\n","\t\t# for faster inference we'll make batch predictions on *all*\n","\t\t# faces at the same time rather than one-by-one predictions\n","\t\t# in the above `for` loop\n","\t\tfaces = np.array(faces, dtype=\"float32\")\n","\t\tpreds = maskNet.predict(faces, batch_size=32)\n","\n","\t# return a 2-tuple of the face locations and their corresponding\n","\t# locations\n","\treturn (locs, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpCnm9-RyXGL"},"outputs":[],"source":["protoPath = \"D:\\\\ML DEEP LEARNING FACE\\\\Masked Face Recognition\\\\face_detector\\\\deploy.prototxt\"\n","weightsPath = \"D:\\\\ML DEEP LEARNING FACE\\\\Masked Face Recognition\\\\face_detector\\\\res10_300x300_ssd_iter_140000.caffemodel\"\n","\n","faceNet = cv2.dnn.readNet(protoPath, weightsPath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1r5a64rLyXGM"},"outputs":[],"source":["maskNet = load_model('D:\\\\ML DEEP LEARNING FACE\\\\Masked Face Recognition\\\\mask_detector.model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QF33sOPuyXGN","outputId":"04a13d9b-c4b0-4753-efbb-257db3982ae6"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"data":{"text/plain":["['RFModel.joblib']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["VGG_model.save('featuresVGG.h5')\n","joblib.dump(RF_model, \"RFModel.joblib\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7q5yoJ7dyXGN","outputId":"1b14ce61-8387-4a6e-e253-3e2137350341"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}],"source":["VGG_model = load_model(\"D:\\\\ML DEEP LEARNING FACE\\\\Masked Face Recognition\\\\featuresVGG.h5\")\n","RF_model = joblib.load(\"D:\\\\ML DEEP LEARNING FACE\\\\Masked Face Recognition\\\\RFModel.joblib\")"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667837392162,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"9wMRjFngyXGO"},"outputs":[],"source":["def predict(img):\n","    if img is None:\n","        return 'Unknown'1\n","    img = cv2.resize(img,(SIZE,SIZE))\n","    input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n","    input_img_feature=VGG_model.predict(input_img)\n","    prediction_RF = RF_model.predict(input_img_feature)[0]\n","    # prediction_RF = RF_model.predict_proba(input_img_feature)\n","    prediction_RF = encoder.inverse_transform([prediction_RF])  #Reverse the label encoder to original name\n","    return str(prediction_RF)\n","    # return prediction_RF"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667837481161,"user":{"displayName":"Geetansh Verma","userId":"07442164100714288716"},"user_tz":-330},"id":"DkpKuvoMyXGO","outputId":"220a4cf2-8324-41dd-cda4-49a4376559c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 27ms/step\n","['/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Sharukh Khan']\n"]}],"source":["img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Masked Face Recognition/MainDataset/Alia Bhatt/6889155f-5d48-11ed-9c5b-90324b084670.jpg')\n","# max = np.max(predict(img))\n","print(predict(img))\n","# max"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rle3ybzhyXGP"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","\n","while True:\n","\t_ , frame = cap.read()\n","\n","\t# detect faces with mask or not\n","\t(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n","\n","\t# loop over the detected face locations\n","\tfor (box, pred) in zip(locs, preds):\n","\t\t(startX, startY, endX, endY) = box\n","\t\t(mask, withoutMask) = pred\n","\n","\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\n","\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n","\n","\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n","\n","\t\tcv2.putText(frame, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n","\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n","\t\tcv2.rectangle(frame, (startX, startY), (endX, endY-100), (0,0,0), 2)\n","\t\timg = frame[startY:endY-100,startX:endX]\n","\t\t\n","\t\tcv2.imshow(\"cut\",img)\n","\t\tname = predict(img)\n","\t\tcv2.putText(frame, name, (endX-20, endY+10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n","  \n","\tcv2.imshow(\"Frame\", frame)\n","\tkey = cv2.waitKey(1) & 0xFF\n","\n","\tif key == ord(\"q\"):\n","\t\tbreak\n","\n","cap.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"}}},"nbformat":4,"nbformat_minor":0}
