{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import dlib\n",
    "import uuid\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ML DEEP LEARNING FACE\\\\Masked Face Recognition\\\\database\\\\Train\\\\Varsha'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATH = os.path.join('D:\\\\ML DEEP LEARNING FACE\\\\Masked Face Recognition\\\\database\\\\Test\\\\Kamya')\n",
    "PATH = os.path.join('D:\\\\ML DEEP LEARNING FACE\\\\Masked Face Recognition\\\\database\\\\Train\\\\Varsha')\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness(img, value=30):\n",
    "    # img = os.path.join(PATH,im)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = cv2.imread('database\\\\Train\\\\Shrey\\\\fb91105e-2af8-11ed-a74f-a42b5c8c19cf.jpg')\n",
    "# img = increase_brightness(im,500)\n",
    "# cv2.imshow(\"img\",img)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "type(np.array(im))\n",
    "# type(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "i = 0\n",
    "while i<15:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        results = detector(frame,1)\n",
    "        if (len(results)>0):\n",
    "            x1 = results[0].left()\n",
    "            y1 = results[0].top()\n",
    "            x2 = results[0].right()\n",
    "            y2 = results[0].bottom()\n",
    "            \n",
    "            if(cv2.waitKey(1) & 0XFF == ord('a')):\n",
    "                img_crop = frame[y1:y2-100,x1:x2]\n",
    "                # img_crop = cv2.resize(img_crop,(200,200))\n",
    "                cv2.imshow(\"crop\",img_crop)\n",
    "                img_name = os.path.join(PATH,'{}.jpg'.format(uuid.uuid1()))\n",
    "                i = i+1\n",
    "                cv2.imwrite(img_name, img_crop)\n",
    "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2, cv2.LINE_AA)\n",
    "            cv2.rectangle(frame, (x1,y1), (x2,y2-100), (0,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"image\",frame)\n",
    "        if(cv2.waitKey(1)==27):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img):\n",
    "    data = []\n",
    "    for i in range(4):\n",
    "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "            \n",
    "        data.append(img)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(os.path.join(PATH)):\n",
    "    img_path = os.path.join(PATH, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    augmented_images = data_aug(img) \n",
    "    \n",
    "    for image in augmented_images:\n",
    "        cv2.imwrite(os.path.join(PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6246b25e200e4c5124e3e61789ac81350562f0761bbcf92ad9e48654207659c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
